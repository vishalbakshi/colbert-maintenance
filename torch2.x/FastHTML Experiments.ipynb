{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad85887-5635-4f0e-bf18-00c5ee680733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install python-fasthtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7320a883-2b1c-4928-b6d3-7adef41cbf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "539343d0-1e51-49b0-9358-bc6e321dfacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "document.body.addEventListener('htmx:configRequest', (event) => {\n",
       "    if(event.detail.path.includes('://')) return;\n",
       "    htmx.config.selfRequestsOnly=false;\n",
       "    event.detail.path = `${location.protocol}//${location.hostname}:8000${event.detail.path}`;\n",
       "});\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fasthtml.common import *\n",
    "from fasthtml.jupyter import *\n",
    "import torch\n",
    "\n",
    "app = FastHTML()\n",
    "count = [0]\n",
    "\n",
    "def _close(a, b, default=False):\n",
    "    gtype = a.dtype\n",
    "    \n",
    "    if gtype in [torch.uint8, torch.int32, torch.int64]:\n",
    "        if a.shape == b.shape: return torch.equal(a,b)\n",
    "        return False\n",
    "    \n",
    "    if not default:\n",
    "        if gtype == torch.float32:\n",
    "            atol, rtol = 1e-6, 1e-5\n",
    "        elif gtype == torch.bfloat16:\n",
    "            atol, rtol = 1e-3, 1e-2\n",
    "        else:\n",
    "            atol, rtol = 1e-4, 1e-3\n",
    "    else:\n",
    "        atol, rtol = 1e-8, 1e-5\n",
    "    return torch.allclose(a, b, rtol=rtol, atol=atol)\n",
    "    \n",
    "@app.route('/')\n",
    "def home():\n",
    "    pytorch_versions = [\"1.13.1\", \"2.0.0\", \"2.0.1\", \"2.1.0\"]\n",
    "    dropdown_a = Select(\n",
    "        Option(\"Select PyTorch Version A\", value=\"\", selected=True),\n",
    "        *[Option(version, value=version) for version in pytorch_versions],\n",
    "        name=\"version_a\",\n",
    "        id=\"version_a\"\n",
    "    )\n",
    "\n",
    "    dropdown_b = Select(\n",
    "        Option(\"Select PyTorch Version B\", value=\"\", selected=True),\n",
    "        *[Option(version, value=version) for version in pytorch_versions],\n",
    "        name=\"version_b\",\n",
    "        id=\"version_b\"\n",
    "    )\n",
    "    return Div(\n",
    "        H1(\"Index Artifact Comparison\"),\n",
    "        dropdown_a,\n",
    "        dropdown_b,\n",
    "        Button(\"Compare\", hx_post=\"/compare\", hx_target=\"#comparison\", hx_include=\"#version_a, #version_b\"),\n",
    "        Div(id=\"comparison\")\n",
    "    )\n",
    "\n",
    "@app.route('/compare')\n",
    "def compare(version_a: str = \"\", version_b: str = \"\"):\n",
    "    path_a = f\"20250915-0.2.22.main.torch.{version_a}-1/indexing/ConditionalQA/\"\n",
    "    path_b = f\"20250915-0.2.22.main.torch.{version_b}-1/indexing/ConditionalQA/\"\n",
    "\n",
    "    a = os.listdir(path_a)\n",
    "    b = os.listdir(path_b)\n",
    "    f_match = 0\n",
    "    for i, f in enumerate(a): \n",
    "        if f == b[i]: f_match += 1\n",
    "            \n",
    "    a_pts = [f for f in a if f.endswith(\".pt\")]\n",
    "    b_pts = [f for f in b if f.endswith(\".pt\")]\n",
    "    \n",
    "    shape_mismatches = 0\n",
    "    shape_count = 0\n",
    "    default = \"False\"\n",
    "    \n",
    "    for i, f in enumerate(a_pts):\n",
    "        a_pt = torch.load(path_a + f)\n",
    "        b_pt = torch.load(path_b + f)\n",
    "        \n",
    "        if isinstance(a_pt, tuple):\n",
    "            shape_count += 2\n",
    "            match1 = a_pt[0].shape == b_pt[0].shape\n",
    "            match2 = a_pt[1].shape == b_pt[1].shape\n",
    "            if not match1: shape_mismatches += 1\n",
    "            if not match2: shape_mismatches += 1\n",
    "        else:\n",
    "            shape_count += 1\n",
    "            match = a_pt.shape == b_pt.shape\n",
    "            if not match: shape_mismatches += 1\n",
    "\n",
    "    value_mismatches = 0\n",
    "    mismatches = []\n",
    "\n",
    "    for i, f in enumerate(a_pts):\n",
    "        a_pt = torch.load(path_a + f)\n",
    "        b_pt = torch.load(path_b + f)\n",
    "        \n",
    "        if isinstance(a_pt, tuple):\n",
    "            if a_pt[0].shape == b_pt[0].shape:\n",
    "                match1 = _close(a_pt[0], b_pt[0], default=default)\n",
    "            else:\n",
    "                match1 = False\n",
    "                \n",
    "            if a_pt[1].shape == b_pt[1].shape:\n",
    "                match2 = _close(a_pt[1], b_pt[1], default=default)\n",
    "            else:\n",
    "                match2 = False\n",
    "                \n",
    "            if not (match1 and match2):\n",
    "                value_mismatches += 1\n",
    "                mismatches.append(f)\n",
    "        else:\n",
    "            if a_pt.shape == b_pt.shape:\n",
    "                match = _close(a_pt, b_pt, default=default)\n",
    "            else:\n",
    "                match = False\n",
    "                \n",
    "            if not match:\n",
    "                value_mismatches += 1 \n",
    "                mismatches.append(f)\n",
    "\n",
    "    if len(mismatches) == 0: mismatches.append(\"All tensors match!\")\n",
    "        \n",
    "    return Div(\n",
    "        H2(f\"Comparing PyTorch {version_a} vs {version_b}\"),\n",
    "        P(f\"{f_match}/{len(a)} file names match\"),\n",
    "        P(f\"{shape_count - shape_mismatches}/{shape_count} Tensor Shapes Match\"),\n",
    "        H3(\"Tensor Value Mismatches\"),\n",
    "        *[P(f, style=\"color: red;\") for f in mismatches]\n",
    "    )\n",
    "\n",
    "# Use port 8000 - Modal forwards this to the tunnel URL\n",
    "server = JupyUvi(app, port=8000, host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c7ec6-5419-400d-b16e-0f72d8a11757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
